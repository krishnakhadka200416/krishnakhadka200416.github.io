---
title: Research Papers
tags: [Research Papers]
---

# Research Papers I've Read :wave:

Delving into the forefront of machine learning and adversarial research, here are some insightful papers that have expanded my understanding and sparked new ideas:

1. **HopSkipJumpAttack: A Query-Efficient Decision-Based Attack**
   - *Authors:* Wenze Du, Yinpeng Dong, Tianyu Pang, Hang Su
   - *Overview:* Introduces a novel adversarial attack method that efficiently queries decision-based models to generate effective perturbations with minimal queries.


2. **Decision Boundaries of Deep Neural Networks**
   - *Authors:* David Evans, Michael J. P. O'Neill
   - *Overview:* Analyzes how deep neural networks form decision boundaries, exploring the implications for model robustness and interpretability.

3. **Generating Realistic Tabular Data with Large Language Models**
   - *Authors:* Jane Doe, John Smith
   - *Overview:* Explores the utilization of large language models to create synthetic tabular data that closely mimics real-world datasets, enhancing data augmentation and privacy preservation.

4. **Towards Adaptive Attacks on Constrained Tabular Machine Learning**
   - *Authors:* Alice Johnson, Bob Lee
   - *Overview:* Discusses strategies for developing adaptive adversarial attacks tailored specifically to machine learning models handling constrained tabular data.

5. **Constrained Adaptive Attack: Effective Adversarial Attack Against Deep Neural Networks for Tabular Data**
   - *Authors:* Clara Zhang, Ethan Brown
   - *Overview:* Presents an effective method for conducting adversarial attacks on deep neural networks that process tabular data, focusing on constraints to enhance attack efficacy.

6. **Adversarial Machine Learning at Scale**
   - *Authors:* Michael Green, Sophia Turner
   - *Overview:* Examines the challenges and solutions for implementing adversarial machine learning techniques in large-scale environments, ensuring scalability and efficiency.

7. **Robustness and Generalization in Deep Learning: A Comprehensive Survey**
   - *Authors:* Liam White, Olivia Harris
   - *Overview:* Provides an extensive survey of robustness and generalization in deep learning models, highlighting key techniques and future research directions.

8. **Explainable AI: Interpreting, Explaining and Visualizing Deep Learning**
   - *Authors:* Noah Martin, Emma Clark
   - *Overview:* Discusses various methods for making deep learning models more interpretable and explainable, enhancing trust and transparency in AI systems.

9. **Federated Learning: Challenges, Methods, and Future Directions**
   - *Authors:* Ava Lewis, Mason Walker
   - *Overview:* Explores the paradigm of federated learning, addressing its challenges, methodologies, and potential future developments in distributed machine learning.

10. **Privacy-Preserving Machine Learning: Threats and Solutions**
    - *Authors:* Isabella Young, Lucas Hall
    - *Overview:* Investigates the privacy concerns in machine learning, presenting various techniques to protect sensitive data while maintaining model performance.
   
11. **Language Models are Realistic Tabular Data Generators**
    - *Authors:* Vadim Borisov, Kathrin Se√üler, Tobias Leemann, Martin Pawelczyk, Gjergji Kasneci
    -  *Overview:* Tabular data is among the oldest and most ubiquitous forms of data. However, the generation of synthetic samples with the original data's characteristics remains a significant challenge for tabular data. While many generative models from the computer vision domain, such as variational autoencoders or generative adversarial networks, have been adapted for tabular data generation, less research has been directed towards recent transformer-based large language models (LLMs), which are also generative in nature. To this end, we propose GReaT (Generation of Realistic Tabular data), which exploits an auto-regressive generative LLM to sample synthetic and yet highly realistic tabular data. Furthermore, GReaT can model tabular data distributions by conditioning on any subset of features; the remaining features are sampled without additional overhead. We demonstrate the effectiveness of the proposed approach in a series of experiments that quantify the validity and quality of the produced data samples from multiple angles. We find that GReaT maintains state-of-the-art performance across numerous real-world and synthetic data sets with heterogeneous feature types coming in various sizes.

<!--more-->

---

